{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5c5936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, IFrame, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from matplotlib          import rc \n",
    "from matplotlib          import cm\n",
    "\n",
    "import pandas as pd\n",
    "import corner\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "import wget\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.optimize as spo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe787d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists('Data'):\n",
    "    os.mkdir('Data')\n",
    "\n",
    "\n",
    "file = 'Data/Rotacion.csv'\n",
    "url = 'https://raw.githubusercontent.com/asegura4488/Database/main/MetodosComputacionalesReforma/DataRotacion.csv'\n",
    "\n",
    "if not path.exists(file):\n",
    "    Path_ = wget.download(url,file)\n",
    "    print('File loaded')\n",
    "else:\n",
    "    Path_ = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6fd4d503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(Path_)\n",
    "\n",
    "hi = data.h\n",
    "ai = data.angle\n",
    "yi = data.y\n",
    "sigmay = data.sigmay\n",
    "\n",
    "len(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3069503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>angle</th>\n",
       "      <th>y</th>\n",
       "      <th>sigmay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        h  angle       y  sigmay\n",
       "20   10.0   30.0  0.0013  0.0015\n",
       "21   20.0   30.0  0.0017  0.0015\n",
       "22   30.0   30.0  0.0038  0.0015\n",
       "23   40.0   30.0  0.0059  0.0015\n",
       "24   50.0   30.0  0.0067  0.0015\n",
       "25   60.0   30.0  0.0094  0.0015\n",
       "26   70.0   30.0  0.0122  0.0015\n",
       "27   80.0   30.0  0.0132  0.0015\n",
       "28   90.0   30.0  0.0151  0.0015\n",
       "29  100.0   30.0  0.0186  0.0015"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data[data['angle'] == 30]\n",
    "H = data1.h\n",
    "A = data1.angle\n",
    "Y = data1.y\n",
    "sigma = data1.sigmay\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d511ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(h,o,a,g):\n",
    "    #a es lambda\n",
    "    yi = 2*np.sqrt(2)*o*np.cos(a*np.pi/180)*np.sqrt((h**3)/g)/3\n",
    "    return yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0d39b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Chi2(o,h,yi,sigmai,a,g):\n",
    "    return np.sum (  (yi-Model(h,o,a,g))**2/(2*sigmai**2) )\n",
    "\n",
    "len(H),len(Y),len(sigma),len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d1d5dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000003\n",
      "         Iterations: 15\n",
      "         Function evaluations: 275\n",
      "         Gradient evaluations: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.57609173e-04, 7.28648693e-05, 8.86592161e-05, 8.94096724e-05,\n",
       "       7.26497170e-05, 7.75385931e-05, 7.98602972e-05, 7.07215657e-05,\n",
       "       6.77991310e-05, 7.13060264e-05])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll = lambda *o: Chi2(*o)\n",
    "\n",
    "sigma1 = np.random.normal(loc=0,scale=20,size=len(Y))\n",
    "sigma1 = np.abs(sigma)\n",
    "\n",
    "PEO=np.ones(10)\n",
    "minimm = spo.minimize( nll, PEO, args=(H,Y,sigma,A,9.8),options={'disp':True} )\n",
    "\n",
    "bestparam = minimm.x\n",
    "bestparam\n",
    "#Se escogió el mejor valor de omega, que es 7.07215657e-05 como se ve en la optimización abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8ab42576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtcklEQVR4nO3deXxW1Z3H8c+PEESLSES0CMRgB1uhnVGMQBdt1VqB2kanUsIwimukhbFarWKxdaUute4LRkWxomDV0agIKq24DCChooIKgtCAhEV2Zcvymz/OjT6G7Dw3T5bv+/V6Xnnuvefce+7V5Me5ZzN3R0REJBnapLoAIiLSciioiIhI0iioiIhI0iioiIhI0iioiIhI0rRNdQFS6YADDvCsrKxUF0NEpFmZN2/ep+7epapjrTqoZGVlUVhYmOpiiIg0K2b2r+qO6fWXiIgkjYKKiIgkjYKKiIgkjYKKiIgkjYKKiIgkjYKKiIgkTaxBxcwGmtkiM1tiZmOqOG5mdkd0/F0z6xvt72Fm/zCzD8xsoZn9JiHP/mb2spl9FP3MSDh2eXSuRWZ2Upz3JiIiu4stqJhZGnA3MAjoDQwzs96Vkg0CekWfPODeaH8pcLG7Hw4MAEYl5B0DzHD3XsCMaJvoeC7QBxgI3BOVQUREGkmcNZV+wBJ3/9jddwGTgZxKaXKARzyYDXQys67uXuzu/wRw963AB0C3hDwTo+8TgVMS9k92953uvgxYEpVBREQSDL1vFkPvmxXLueMMKt2AFQnbK/kyMNQ5jZllAUcCc6JdB7l7MUD088B6XA8zyzOzQjMrXLduXX3uR0REahFnULEq9lVeZrLGNGbWAXgKuNDdtyTherh7vrtnu3t2ly5VTl0jIiINFGdQWQn0SNjuDqyqaxozSycElEnu/nRCmjVm1jVK0xVYW4/riYhIjOIMKnOBXmbW08zaERrRCyqlKQDOiHqBDQA2u3uxmRnwIPCBu99SRZ4R0fcRwLMJ+3PNbC8z60lo/H8r+bclIiLViW2WYncvNbPRwHQgDZjg7gvNbGR0fDwwFRhMaFTfBpwVZf8+cDrwnpnNj/b93t2nAjcAT5jZOUARMCQ630IzewJ4n9B7bJS7l8V1fyIisrtYp76PgsDUSvvGJ3x3YFQV+d6g6jYS3H09cEI1x8YB4/agyCIisgc0ol5ERJJGQUVERJJGQUVERJJGQUVERJJGQUVERJJGQUVEpBWZNAnmzIGZMyErK2wnk4KKiEgrMWkS5OXBzvIS0jpup7hkI3l5yQ0sCioiIq3E2LFQ2mkj7Q7cStv9tnNQ7mxKO21k7NjkXUNBRUSklSgqgvaZ6zFzzMDalNM+cz1FRcm7hoKKiEgrkdWjjNOLnqZ96S7alJfh5W3YUdSZzMzkXUNBRUSkNfj0U97YbzB3rbqMM197gfJN7VkzeQBtN2UwLomTW8U695eIiDQBc+fCaadx8OrVzD4nn/FlfdjxmdE1PYNx+TB8ePIupaAiItJSuUN+PlxwAXTtCm++yYDsbPpHSwlPeSz5l9TrLxGRlmjbNjjzTBg5Eo4/HubNg+zs2C+roCIi0tIsXQrf/S789a9w5ZXwwgvQuXOjXDrWoGJmA81skZktMbMxVRw3M7sjOv6umfVNODbBzNaa2YJKeaaY2fzos7xiES8zyzKz7QnHxiMi0to89xwcdRSsWBGCyVVXQZvGqz/E1qZiZmnA3cCJhPXj55pZgbu/n5BsEGHZ315Af+De6CfAw8BdwCOJ53X3oQnX+AuwOeHwUnc/Iqk3IiLSHJSVwR//CH/6UwgqTz4Z5mFpZHGGr37AEnf/2N13AZOBnEppcoBHPJgNdDKzrgDu/hqwobqTR+vY/xJ4PJbSi4g0F+vWwUknhYBy3nnwxhspCSgQb1DpBqxI2F4Z7atvmuocA6xx948S9vU0s7fNbKaZHVPfAouINDtz5kDfviGQTJgQenu1b5+y4sQZVKpaY94bkKY6w/hqLaUYyHT3I4HfAo+ZWcfdCmWWZ2aFZla4bt26Ol5KRKSJcYd77oFjjoH0dJg1C846K9WlijWorAR6JGx3B1Y1IM1uzKwt8J/AlIp97r7T3ddH3+cBS4HDKud193x3z3b37C5dutTxVkREmpDPP4czzoBRo+AnPwndhY88MtWlAuINKnOBXmbW08zaAblAQaU0BcAZUS+wAcBmdy+uw7l/DHzo7isrdphZl6hzAGZ2KKHx/+Nk3IiISJPx0UcwYECYr/7aa6GgADIyUl2qL8TW+8vdS81sNDAdSAMmuPtCMxsZHR8PTAUGA0uAbcAXdTczexz4EXCAma0ErnT3B6PDuezeQH8scI2ZlQJlwEh3r7ahX0Sk2XnmGRgxIrzumjYt1FIaYMr5301uuRKYe12bMFqe7OxsLywsTHUxRERqVloaFkO56SY4+mj429/gkENSVhwzm+fuVQ7P19xfIiJN2Zo1MGwY/OMfYcqV226DvfZKdamqpaAiItJU/d//wZAhsGEDTJwYGuebOM39JSLS1LjDnXfCD38Ie+8Ns2c3i4ACCioiIo1m6H2zGBpNO1+tzz4LC5xccAEMGgSFhfAf/9E4BUwCBRURkaZi0SLo3x+mTAlTrjzzDHTqlOpS1YvaVEREmoKnngoj4tu3h5deghNOSHWJGkQ1FRGRVCothUsugdNOg9694Z//bLYBBVRTERFJndWrYehQeO21MOXKLbdAu3apLtUeUVAREUmFN96AX/4SNm2CRx8NjfMtgF5/iYg0Jne49Vb40Y+gQ4cwdX0LCSigmoqISKNpv+Nzzv/rDTBvBpx6Kjz0EOy3X6qLlVQKKiIijWH+fK6//hy+vnYl3Hgj/O53YFUtKdW86fWXiEic3OGuu6B/f9rv2MY1F90Jl17aIgMKqKYiIhKfDRvg7LPh2Wfhpz/l0uNGsbVDp1SXKlaqqYiIxOGNN+CII2Dq1NAw/9xzLT6ggIKKiEhylZXBddeFySDbtQtrx194IZMeM+bMgZkzISsrLNzYEsUaVMxsoJktMrMlZjamiuNmZndEx981s74JxyaY2VozW1Apz1Vm9omZzY8+gxOOXR6da5GZnRTnvYmI7GbVKjjxRPjDHyA3N4yOP+ooJk2CvDzYWV5CWsftFJdsJC+vZQaW2IJKtF783cAgoDcwzMx6V0o2iLCWfC8gD7g34djDwMBqTn+rux8RfaZG1+tNWGa4T5Tvnoo160VEYvfii2E24TlzQlfhRx+Fjh2BsGhjaaeNtDtwK233285BubMp7bSRsWNTXOYYxFlT6QcscfeP3X0XMBnIqZQmB3jEg9lAJzPrCuDurwH1WWM+B5js7jvdfRlh3ft+e3wXIiI12bUrzN01eDAcfDDMmwdnnvmV3l1FRdA+cz1Y2G1tymmfuZ6iotQVOy5xBpVuwIqE7ZXRvvqmqcro6HXZBDPLqM+5zCzPzArNrHDdunV1uJSISDWWLoXvfx/+8pcwd9ecOfCtb+2WLDMTdhR1Bg89jL28DTuKOpOZmYIyxyzOoFJVJ2xvQJrK7gW+ARwBFAN/qc+53D3f3bPdPbtLly61XEpEpBqTJ8ORR8KSJfD002EsSvv2VSYdNw7abspg19p9Kd28N2smD6DtpgzGjWvkMjeCOIPKSqBHwnZ3YFUD0nyFu69x9zJ3Lwfu58tXXPU+l4hIvX3+OZx7LgwbBt/5DsyfH6ZcqcHw4ZCfD3u1Sadsy950Tc8gP79FTfn1hTiDylygl5n1NLN2hEb0gkppCoAzol5gA4DN7l5c00kr2lwipwIVvcMKgFwz28vMehIa/99Kxo2ISPNWp2V86+K99+Doo2HChND6PnMmHHJInbIOHx4WdfzhD2H58pYZUCDGEfXuXmpmo4HpQBowwd0XmtnI6Ph4YCowmNCovg04qyK/mT0O/Ag4wMxWAle6+4PATWZ2BOHV1nLg/Oh8C83sCeB9oBQY5e5lcd2fiLQi7nDffXDRRWF535dfbtYLacUp1mlaou6+UyvtG5/w3YFR1eQdVs3+02u43jigBb6lFJGU2bQpvO566ik46SR45BE48MBUl6rJ0oh6EZHqzJoVplp59lm46aYw5YoCSo0UVEREKisvhxtugGOOCQNL3ngjTFXfRn8ya6NZikVEEq1eDaefDq+8AkOGwP33t7iFtOKkoCIiUuGll0JA2bIl9AE+99wWu+5JXFSXExEpKYExY0JDfJcuUFgI552ngNIAqqmISOu2bBn813/B7NlhKuFbb4V99kl1qZotBRURab2efDK84nKHJ54IbSiyR/T6S0Rik7SR7Mm2fTuMHBmCyDe/GaZaUUBJCtVURKRFmzQpTB68YwdkXQ93/WohJz+aCwsWwKWXhlUa09MbpSxTzv9uo1wnlVRTEZEW6ysrLu67jeySiRw/5mh2FK2BadPgxhsbLaC0FgoqItJiVay4uNeBW2m33zYW5O7LXw/+Bcfs+07o6SVJp6AiIi1WURH0zpxLG8rwNm3Y2aYdl2X+kXmrutaeWRpEQUVEWqbt28nv8FseKPoN6WVl4E5ZeRrbiw5okSsuNhUKKiLS8sybB0cdxblbb2Xu2hPYtbYDJZv3adErLjYVCioi0nKUlsK118KAAbB5M0yfzr4P34Wnd2jxKy42FbEGFTMbaGaLzGyJmY2p4riZ2R3R8XfNrG/CsQlmttbMFlTK82cz+zBK/79m1inan2Vm281sfvQZj4i0HosXw/e/D3/8YxhzsmAB/OQnrWbFxaYitqBiZmnA3cAgoDcwzMx6V0o2iLDsby8gD7g34djDwMAqTv0y8G13/3dgMXB5wrGl7n5E9BmZlBsRkabNHe6+O6x78tFHMHkyPPYYZGSkumStUpw1lX7AEnf/2N13AZOBnEppcoBHPJgNdKpYg97dXwM2VD6pu7/k7qXR5myge2x3ICJN2yefhK7Bo0eHqsiCBTB0aKpL1arFGVS6ASsStldG++qbpiZnAy8mbPc0s7fNbKaZHVNVBjPLM7NCMytct25dPS4lIvVRMZJ95kzIygrbSfX44/Dtb8Obb8K994ZVGQ8+OMkXkfqKM6hUNWe0NyBN1Sc3GwuUAhX/qxYDme5+JPBb4DEz67jbyd3z3T3b3bO7dOlSl0uJSD19ZSR7x+0Ul2wkLy9JgWXDBsjNDTMLf+tbYd6ukSM1TX0TEWdQWQn0SNjuDqxqQJrdmNkI4GRguLs7gLvvdPf10fd5wFLgsAaXXkQarGIke7sDt9J2v+0clDub0k4bGTt2D088bVqonTz1FIwbB6+/Dr16JaXMkhxxBpW5QC8z62lm7YBcoKBSmgLgjKgX2ABgs7sX13RSMxsIXAb83N23JezvEnUOwMwOJTT+f5y82xGRuioqgvaZ68FCBcLalNM+cz1FRQ084Wefwa9+BYMGwf77w1tvwe9/D201J25TE1tQiRrTRwPTgQ+AJ9x9oZmNNLOKnllTCX/4lwD3A7+uyG9mjwOzgG+a2UozOyc6dBewL/Bypa7DxwLvmtk7wJPASHffraFfROKXmQk7ijqDh85ZXt6GHUWdGzaSfdas0LPrvvvgkkvCqoxHHpnsIkuSxBrm3X0qIXAk7huf8N2BUdXkHVbN/n+rZv9TwFMNLqyIJM24cZCXl8GutfvSpn0pnz53ZBjJnl+Pk+zaBVdfDTfcAD16wD/+EXp4SZOmuqOIJF3FAMOxM9LZsSWdrukhoNR54OGCBXD66aER/uyzwxK/HXfrdyNNkIKKiMRi+HAo+Cx8n/JYHTOVlcFtt4X2kv32g2eegZzKw9ukKVNQEZGmYflyGDECXnsNTjkltKEceGBSTt0aVlxsKjShpIikljs89BD8+7/D22+H708/nbSAIo1LQUVEUmftWjj11NBuctRR8N57cOaZGsjYjCmoiEhqPPNMGMg4bRrccgvMmAGHHJLqUskeUlARkca1eXOojZx6KnTvHhbUuugiaKM/Ry2B/iuKSON59dXQdvLXv8IVV8Ds2dCnT6pLJUmkoCIi8duxA377WzjuONhrrzCz8LXXQrt2qS6ZJJm6FItIrHoWLYKjzoX334df/xpuugm+9rVUF0tioqAi0kINvW8WkMIxGjt3MqTgfk6Z9gh8/aDQIH/SSakpizSaaoOKmd1Rh/xb3P2KJJZHRFqCN9+Ec8/ltA8/5LX+Azl26qQwu7C0eDW1qeQA82r5/CLuAopIM7JlC4waBT/4AWzfDtOmcezsFxVQWpGaXn/d6u4Ta8psZhlJLo+INFfPPx/WPPnkE7jwwtAQ36FDqksljazamoq731Zb5rqkEZEWbu1aGDYMfvYz6NQprH9y660KKK1UrV2Ko5UbbzGzp82soOJTl5Ob2UAzW2RmS8xsTBXHzczuiI6/a2Z9E45NMLO1ZragUp79zexlM/so+pmRcOzy6FyLzEwtgiJxcoeJE+Hww8NcXddeGwYy9u+f6pJJCtVlnMozwHLgTuAvCZ8aRUv73g0MAnoDw8ysd6VkgwjL/vYC8oB7E449DAys4tRjgBnu3guYEW0TnTsX6BPlu6dieWERSbJly0JPrjPPhN694Z13wmBGjTtp9erSpXiHu9elJ1hl/YAl7v4xgJlNJjT+v5+QJgd4JFoBcraZdTKzru5e7O6vmVlWFefNAX4UfZ8IvEpYsz4HmOzuO4FlZrYkKsOsBpRdRKpSVga33w5/+AOkpcE998D552uKFflCXYLK7WZ2JfASsLNip7v/s5Z83YAVCdsrgcr14qrSdAOKazjvQe5eHJWh2Mwq5sfuBsyu4lwikgzvvgvnngtz58LJJ4eA0qNHqkslTUxdgsp3gNOB44HyaJ9H2zWpau5qb0CauqrTucwsj/CqjczMzAZeSqQV2bEjtJfcdFPoGjxlCgwZounppUp1CSqnAoe6+656nnslkPjPmO7AqgakqWxNxSsyM+sKrK3Pudw9H8gHyM7ObmgAE2kdXnsNzjsPFi8O7Sc33wydO6e6VNKE1eVF6DtApwacey7QK+o91o7QiF6511gBcEbUC2wAsLni1VYNCoAR0fcRwLMJ+3PNbC8z60lo/H+rAeUWafYmTYI5c2DmTMjKCtv1snlzGHPywx9CSQm89FJYkVEBRWpRl5rKQcCHZjaXr7ap/LymTO5eamajgelAGjDB3Rea2cjo+HhgKjAYWAJsA86qyG9mjxMa5A8ws5XAle7+IHAD8ISZnQMUAUOi8y00sycIHQFKgVHuXlaH+xNpUSZNgrw86DikhLSOpRSXbCQvL/S8Hz68Did49tkw8ePq1XDxxXD11ZoAUurMQserGhKY/bCq/e4+M5YSNaLs7GwvLCxMdTFEkiorC4pLNvL14f8HBl7ahjWTB9A1PYPly2vIuHo1/M//wJNPhjVPHngAjj66kUotzYmZzXP37KqO1VpTaQnBQ6Q1KSqCffuvB4va0tuU0z5zPUVzqplVyT282rr44jBf17hx8LvfQXp6o5ZbWoZq21TM7PnaMtcljYg0rsxM2FHUGTzECy9vw46izlTZ2XHpUvjxj+Gcc0Lt5J134Pe/V0CRBquppvKDWqZjMcJIeRFpQsaNg7y8DHat3Zc27Uv59Lkjabspg3H5CYlKS8P8XFdeGQLI+PGhl5cGMcoeqimo5EQ//53QXXdDFWnq281YRGJW0Rg/dkY6O7ak0zU9BJQvGunnzw81k3/+E3Jy4O67oZvGCUtyVBtUKtpSzOxE4DfAP4EJwHSvrXVfRFJq+HAo+Cx8n/JYtHP7drjmGvjzn+GAA+Bvf4Nf/EKDGCWpaq3rRis79gIeBM4EPjKzP5nZN2Ium4gky6uvhjaTG26AESPCevGnnaaAIklXpxeoUc1kdfQpBTKAJ83sphjLJiJ7aJ9tW8OgleOOg/JyeOUVePBBrcQosam1S7GZXUAYuf4p8ADwO3cvMbM2wEfApfEWUUTqzZ1+b7/KWZNvga0bQhfhq66CffZJdcmkhavLiPoDgP90938l7nT3cjM7OZ5iiUiDLV4Mv/kNF0+bxrIevdh/xjQ46qhUl0paiboMfvxjDcc+SG5xRKTBtm6F664LXYX33puJp13A9ONO4zEFFGlE6pQu0ty5w2OPwbe+FaanHz4cFi9m6o9zKUury8sIkeRRUBFpzt55J8wkPHw4HHwwzJoVplw56KBUl0xaKQUVkSQbet8sht4X8yrWGzbA6NHQty988AHcf3+Y637AgHivK1IL1Y1FmpOystAl+Pe/h40bwxT111wDGdVMFinSyFRTEWkuZs2C/v3h/POhTx94+224804FFGlSVFMRaepWr4YxY2DixDBH1+OPw9ChtY6Gn3L+dxupgCJfirWmYmYDzWyRmS0xszFVHDczuyM6/q6Z9a0tr5lNMbP50We5mc2P9meZ2faEY+PjvDeR2JWUwC23wGGHhd5dY8bAhx9Cbq6mV5EmK7aaipmlAXcDJxJmOZ5rZgXu/n5CskGEecV6Af2Be4H+NeV196EJ1/gLsDnhfEvd/Yi47kmk0bzyClxwQWiEHzwYbrsNevVKdalEahVnTaUfsMTdP3b3XcBkvpxOv0IO8IgHs4FOZta1LnnNzIBfAo/HeA8ijetf/woTPZ54IuzaBc89By+8oIAizUacQaUbsCJhe2W0ry5p6pL3GGCNu3+UsK+nmb1tZjPN7JiqCmVmeWZWaGaF69atq/vdiMSpYlr6ww+HF18MI+MXLICTNROSNC9xNtRX9dK38jos1aWpS95hfLWWUgxkuvt6MzsKeMbM+rj7lq+cxD0fyAfIzs7WujAtSMXYkGbVQO0OBQVw4YWwfDn88pdw883Qo0eqSybSIHHWVFYCib8Z3YFVdUxTY14zawv8JzClYp+773T39dH3ecBS4LA9vguRuCxaBIMGwSmnQIcO8Pe/w5QpCijSrMUZVOYCvcysp5m1A3KBymveFwBnRL3ABgCb3b24Dnl/DHzo7isrdphZl6iBHzM7lND4/3FcNyfSYFu3wqWXwne+A7Nnw+23hzEnxx2X6pKJ7LHYXn+5e6mZjQamA2nABHdfaGYjo+PjganAYGAJsA04q6a8CafPZfcG+mOBa8ysFCgDRrr7hrjuT6TeKiZ+/N3voLgYzj4brr8eDjww1SUTSZpYBz+6+1RC4EjcNz7huwOj6po34diZVex7CnhqD4orsscmTQpTcO3YAVnXw7hxYa5H5s+H//kfeOMNOPpo+N//DaPjRVoYTdMikiSTJoWVe3eWl5DWcTvFJRu57LwNLP7xr8MiWYsWwQMPhFdeCijSQimoiCTJ2LFQ2mkj7Q7cStv9ttMt9w0eyRjEoTPyw4zCixfDOedAG/3aScul/7tFkqSoCNpnrsfMMQNrU84LmT+iL2+HxvhOnVJdRJHYKaiIJMnxX3+fq4r+TPvSXbQpL8PL07ir6DK2HPKdVBdNpNFolmKRPbViBVx5JS+tnshW78DywgwKvnkcq17oR9tNGYzLT3UBRRqPgopIQ61fH7oE33UXAG1+exEv/dvlPPvWYnZ8Bl3TQ0AZPjzF5RRpRAoqIvX1+edh1uCbboLPPoMRI+CqqyAzkyHAk9EkQ1MeS2EZRVJEbSrSIlSMD5k5E7KywnbSlZTAPffAN74BV1wRRsC/+y5MmACZmTFcUKT5UVCRZq+q8SF5eUkMLOXlMHlymEF41KiwaNabb8Izz4RlfUXkCwoq0uxVHh9yUO5sSjttZOzYPTyxO0yfDtnZMGwYfO1rYW2TmTPhe99LStlFWhoFFWn2KsaHYHwxPqR95nqKivbgpG+9BSecAAMHwqZN8OijYdLHwYO1lK9IDRRUpNnLzIQdRZ3BQ+XCy9uwo6hzw5o5PvwwrLzYv39YJOuOO8K+4cM1El6kDvRbIs3euHHQdlMGu9buS+nmvVkzeUAYHzKuHif55BM47zz49rfDK6+rroKlS8MkkO3axVV0kRZHXYql2asYBzJ2Rjo7tqTXb3zIhg1w442hRlJWFuboGjsWunSJtcwiLZWCirQIw4dDwWfhe53Gh2zbFgLJjTfC5s1w+ulw9dWhP7KINFisr7/MbKCZLTKzJWY2porjZmZ3RMffNbO+teU1s6vM7BMzmx99BiccuzxKv8jMTorz3uRLQ++b9cX68E1eSQnk50OvXnD55fCDH8A778DEiQooIkkQW00lWtr3buBEwprzc82swN3fT0g2iLDsby+gP3Av0L8OeW9195srXa83YUXIPsDBwCtmdpi7l8V1j9KMuMOTT4ZBi4sXhy7BU6aEoJJkU87/btLPKdJcxFlT6QcscfeP3X0XMBnIqZQmB3jEg9lAJzPrWse8leUAk919p7svIyxR3C+ZNyTN1CuvhNUWf/lLSE+HgoKwAmMMAUWktYszqHQDViRsr4z21SVNbXlHR6/LJphZRj2uh5nlmVmhmRWuW7euPvcjzc28eXDiieGzbh08/HB41fWzn2msiUhM4gwqVf3Weh3T1JT3XuAbwBFAMfCXelwPd89392x3z+6iHj4t0+LFMHRoGAn/9ttw661hKd8RIyAtLdWlE2nR4uz9tRLokbDdHVhVxzTtqsvr7msqdprZ/cDz9bietGAZm9bxixceglHPQfv28Ic/wCWXQMeOqS6aSKsRZ01lLtDLzHqaWTtCI3pBpTQFwBlRL7ABwGZ3L64pb9TmUuFUYEHCuXLNbC8z60lo/H8rrpuTJmTJEjj/fO684jSO+7/n4Ve/CgMXr7lGAUWkkcVWU3H3UjMbDUwH0oAJ7r7QzEZGx8cDU4HBhEb1bcBZNeWNTn2TmR1BeLW1HDg/yrPQzJ4A3gdKgVHq+dXCzZ8PN9wAf/sbpKfzj++dzHMn/hd3XnFaqksm0mrFOvjR3acSAkfivvEJ3x0YVde80f7Ta7jeOKA+k3NIc+MOr78eVlycNg323Te84rrwQh4sWJ7q0om0ehpRL81DeXmYdv7662HWrDCNyrhx8OtfQ6dOAEw5v2vN5xCR2CmoSNNWUhIGKd54Y5g1+JBDwprwZ58Ne++d6tKJSCUKKtI0bd8elum9+WZYvjyssPjXv4auwunpqS6diFRDU9/LHkn62vCbNsGf/hRqJKNHQ9euYQT8u+/Cf/+3AopIE6egIg2W1LXhV6+Gyy4LK26NHQtHHRUi1ZtvhhHwWiBLpFnQb6o0WFLWhl+6FEaODNWcm28Oy/W+/Ta8+CIce6ymUxFpZhRUpMH2aG34d96BYcPgsMPgoYfCFCqLFsHkyXDEEXEXXURiooZ6abDMTCiuWBueOq4N//rrYcDi1KnQoQNcfDFcdFFoOxGRZk81FWmwOq8N7w7PPx+mmj/2WHjrLbjuulDVuekmBRSRFkQ1FWmwWteGLy39cozJe++Fqs2dd4YxJvvsk7Jyi0h8FFRkj1S5Nvz27aGd5M9/DmNMeveGRx6B3Fx1CRZp4RRUJHk2b4Z77oHbboO1a2HAALj9djj5ZHUJFmklFFSasaH3zQJSvyZ6xqZ1DPzHk3Dps7BlC5x0Elx+uboEi7RCCirSMGVlMH065Odz93PPY14OQ4aEAYx9+6a6dCKSIgoqUj8rVoQ5uR58MHw/8ECeO3EYf//Bz7njiiGpLp2IpFisL7rNbKCZLTKzJWY2porjZmZ3RMffNbO+teU1sz+b2YdR+v81s07R/iwz225m86PP+MrXkwYqLYXnngvTpWRlwVVXweGHw5NPwooVPH7qr1nTpXuqSykiTUBsNRUzSwPuBk4krB8/18wK3P39hGSDCMv+9gL6A/cC/WvJ+zJwebQ65I3A5cBl0fmWuvsRcd1ToqbSnhGrf/0r1EgmTIBPPoGvfx3GjIFzzoFDD0116USkCYrz9Vc/YIm7fwxgZpOBHMJyvxVygEeiFSBnm1mnaA36rOryuvtLCflnA1o7NplKSsJiWPn5YWVFgIEDwxomP/2pugSLSI3iDCrdgBUJ2ysJtZHa0nSrY16As4EpCds9zextYAtwhbu/3rCit0LLlsEDD4TxJcXFcPDBcMUVoVZyyCGpLp2INBNxBpWq+pJ6HdPUmtfMxgKlQMVE68VApruvN7OjgGfMrI+7b6mULw/IA8iscZKqVqCkJKxVkp8PL78cuv8OHgznnRd+tlU/DhGpnzj/aqwEeiRsdwdW1TFNu5rymtkI4GTghOjVGe6+E9gZfZ9nZkuBw4DCxAu6ez6QD5CdnV05yLUOS5d+WStZswa6d4crrwzTp/ToUXt+EZFqxBlU5gK9zKwn8AmQC/xXpTQFwOiozaQ/sNndi81sXXV5zWwgoWH+h+6+reJEZtYF2ODuZWZ2KKHx/+MY76952bULnnkm1EpmzIC0tNBGkpcX2kzS0hp86hbdWUFE6iW2oBL1zhoNTAfSgAnuvtDMRkbHxwNTgcHAEmAbcFZNeaNT3wXsBbxsYbT2bHcfCRwLXGNmpUAZMNLdN8R1f83G4sVw//0wcSKsWxfaR669Fs46C7p1S3XpRKSFifWlubtPJQSOxH3jE747MKqueaP9/1ZN+qeAp/akvM1JxdrwO3ZA1vVhGvovZgfeuROefjrUSl59NdRCcnJCW8mJJ+5RrUREpCZqiW2GKtaG7zikhLSOpdHa8Bl0XPUhP1sd1UrWr4eePeFPf4Izz9SaJSLSKBRUmqHEteHNoFvum4yd/Cg/u3RK6LF1yikh6pxwgmYHFpFGpaDSDH36r8/pO+B1VmO4tcHalPFJZgaXrbqRG1eOgIMOSnURRaSV0j9jG6CiPWPmzDAV1qRJtWbZc6tXh27AP/sZn9oB3FV0Ge3KSrDycsrL2/KnouuYcsilCigiklKqqdRTde0ZkNBQngzu8MEHYXDis8+GKOYOhxzC8hPz+MPMHD7/1PC9nU+fOzKsDZ+fxOuLiDSAair1lNie0Xa/7RyUO5vSThsZOzYJJy8thddeg0sugcMOgz59wmJXJSVw9dXwzjuwbBnfmn47wx88nrZp7Snbsjdd0zPIz09yUBMRaQDVVOqpqAj27b8eLFrUsE057TPXUzQno2En/OwzeOmlUBt54YXQa6tdOzj+ePjtb8N08913n1a+yrXhRURSTEGlnjIzobioM3iYjMzL27CjqDP1mkasuDisT/Lss2F0+86dkJERRrj//OdhOd6OHeO6BRGR2Cio1NO4cZCXl8GutfvSpn1p3doz3GHhwi/bR956K+zv2RN+9aswMPH739e08iLS7Cmo1FNFu8XYGens2JJO1/QQUHZrzygthTfeCEGkoAA+jqYh69cPrrsuBJI+faJ3aCIiLYOCSgNU256xdStMn/5l+8jGjbDXXmEQ4qWXhvaRgw9OSZlFRBqDgsqeWrXqy9daf/97mA14//1DAKloH+nQIdWlFBFpFAoqDbFqFf859SGy33kdRn4Y9n3jGzB6dHit9b3vaYErEWmV9JevIT79lKEF97O4Z58wYWNODhx+uNpHRKTVU1BpiO98h7wbn2Pzfp21QJWISAKNqG8IMzbv1znVpRARaXJiDSpmNtDMFpnZEjMbU8VxM7M7ouPvmlnf2vKa2f5m9rKZfRT9zEg4dnmUfpGZnRTnvYmIyO5iCypmlgbcDQwCegPDzKx3pWSDCGvJ9wLygHvrkHcMMMPdewEzom2i47lAH2AgcE90nhZryvnf1es3EWlS4qyp9AOWuPvH7r4LmAzkVEqTAzziwWygk5l1rSVvDjAx+j4ROCVh/2R33+nuywjr3veL6d5ERKQKcQaVbsCKhO2V0b66pKkp70HuXgwQ/TywHtfDzPLMrNDMCtetW1evGxIRkZrFGVSq6l/rdUxTl7wNuR7unu/u2e6e3aVLl1pOKSIi9RFnl+KVQI+E7e7AqjqmaVdD3jVm1tXdi6NXZWvrcb2kUVuGiMju4qypzAV6mVlPM2tHaEQvqJSmADgj6gU2ANgcvdKqKW8BMCL6PgJ4NmF/rpntZWY9CY3/b8V1cyIisrvYairuXmpmo4HpQBowwd0XmtnI6Ph4YCowmNCovg04q6a80alvAJ4ws3OAImBIlGehmT0BvA+UAqPcvSyu+xMRkd2Ze21NFS1Xdna2FxYWproYIiLNipnNc/fsqo5pRL2IiCSNgoqIiCSNgoqIiCSNgoqIiCSNgoqIiCSNgoqIiCRNq+5SbGbrgH+luhx76ADg01QXognR8/gqPY8v6Vl81Z48j0Pcvcp5rlp1UGkJzKywuv7irZGex1fpeXxJz+Kr4noeev0lIiJJo6AiIiJJo6DS/OWnugBNjJ7HV+l5fEnP4qtieR5qUxERkaRRTUVERJJGQUVERJJGQaUZMbMeZvYPM/vAzBaa2W+i/fub2ctm9lH0MyPVZW0sZpZmZm+b2fPRdmt+Fp3M7Ekz+zD6f+S7rfx5XBT9niwws8fNrH1reR5mNsHM1prZgoR91d67mV1uZkvMbJGZnbQn11ZQaV5KgYvd/XBgADDKzHoDY4AZ7t4LmBFttxa/AT5I2G7Nz+J2YJq7fwv4D8JzaZXPw8y6ARcA2e7+bcJif7m0nufxMDCw0r4q7z36G5IL9Iny3GNmaQ29sIJKM+Luxe7+z+j7VsIfjW5ADjAxSjYROCUlBWxkZtYd+CnwQMLu1vosOgLHAg8CuPsud99EK30ekbbA3mbWFtgHWEUreR7u/hqwodLu6u49B5js7jvdfRlhJd5+Db22gkozZWZZwJHAHOAgdy+GEHiAA1NYtMZ0G3ApUJ6wr7U+i0OBdcBD0evAB8zsa7TS5+HunwA3E5YcLwY2u/tLtNLnEanu3rsBKxLSrYz2NYiCSjNkZh2Ap4AL3X1LqsuTCmZ2MrDW3eeluixNRFugL3Cvux8JfE7LfbVTq6i9IAfoCRwMfM3M/ju1pWqyrIp9DR5roqDSzJhZOiGgTHL3p6Pda8ysa3S8K7A2VeVrRN8Hfm5my4HJwPFm9iit81lA+NflSnefE20/SQgyrfV5/BhY5u7r3L0EeBr4Hq33eUD1974S6JGQrjvhVWGDKKg0I2ZmhHfmH7j7LQmHCoAR0fcRwLONXbbG5u6Xu3t3d88iNDL+3d3/m1b4LADcfTWwwsy+Ge06AXifVvo8CK+9BpjZPtHvzQmENsjW+jyg+nsvAHLNbC8z6wn0At5q6EU0or4ZMbMfAK8D7/FlO8LvCe0qTwCZhF+mIe5euZGuxTKzHwGXuPvJZtaZVvoszOwIQqeFdsDHwFmEfzi21udxNTCU0GvybeBcoAOt4HmY2ePAjwjT268BrgSeoZp7N7OxwNmEZ3Whu7/Y4GsrqIiISLLo9ZeIiCSNgoqIiCSNgoqIiCSNgoqIiCSNgoqIiCSNgoqIiCSNgopIIzKzrMTpyBP2vxpNO/7zepxrbzObb2a7zOyA5JZUpGHaproAIvKF4e5eWNfE7r4dOCKaqkakSVBNRaTxpZnZ/dECUi+Z2d6VE0Q1l1vN7LVowa2jzezpaIGl61JRaJG6UFARaXy9gLvdvQ+wCfhFNel2ufuxwHjCPE2jgG8DZ0bT0Yg0OQoqIo1vmbvPj77PA7KqSVcQ/XwPWBgt0raTMK9Xj2ryiKSUgopI49uZ8L2M6ts2K9KVV8pTXkMekZRSUBERkaRRUBERkaTR1PciTYCZvUpYE6bOXYoT8i4Hst3902SXS6S+VFMRaRo2AA83ZPAjkM6Xi7aJpJRqKiIikjSqqYiISNIoqIiISNIoqIiISNIoqIiISNL8P3m4EEDHuo6XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(H,Model(H,7.07215657e-05,A,9.8),color='r')\n",
    "plt.xlabel('h[m]')\n",
    "plt.ylabel('y[m]')\n",
    "\n",
    "plt.errorbar(H,Y,yerr=sigma1,fmt='.')\n",
    "plt.scatter(H,Y,color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "67e8b3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7271\n",
      "         Gradient evaluations: 119\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6966\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6295\n",
      "         Gradient evaluations: 103\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7393\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6966\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7210\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7515\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7820\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 8186\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6661\n",
      "         Gradient evaluations: 109\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7759\n",
      "         Gradient evaluations: 127\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7515\n",
      "         Gradient evaluations: 123\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6600\n",
      "         Gradient evaluations: 108\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7576\n",
      "         Gradient evaluations: 124\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7393\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6356\n",
      "         Gradient evaluations: 104\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7454\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7210\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 8125\n",
      "         Gradient evaluations: 133\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6966\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7210\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7576\n",
      "         Gradient evaluations: 124\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7454\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 8186\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6478\n",
      "         Gradient evaluations: 106\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7088\n",
      "         Gradient evaluations: 116\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7454\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7759\n",
      "         Gradient evaluations: 127\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7088\n",
      "         Gradient evaluations: 116\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 8003\n",
      "         Gradient evaluations: 131\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 66\n",
      "         Function evaluations: 6722\n",
      "         Gradient evaluations: 110\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6905\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7149\n",
      "         Gradient evaluations: 117\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7454\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 8247\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7271\n",
      "         Gradient evaluations: 119\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7637\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 68\n",
      "         Function evaluations: 5185\n",
      "         Gradient evaluations: 85\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 8064\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 8186\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7637\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6661\n",
      "         Gradient evaluations: 109\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7210\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7820\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7088\n",
      "         Gradient evaluations: 116\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7393\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6783\n",
      "         Gradient evaluations: 111\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6173\n",
      "         Gradient evaluations: 101\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6600\n",
      "         Gradient evaluations: 108\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7393\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7332\n",
      "         Gradient evaluations: 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7210\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 7636\n",
      "         Gradient evaluations: 125\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6905\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7942\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6905\n",
      "         Gradient evaluations: 113\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7027\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7759\n",
      "         Gradient evaluations: 127\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7271\n",
      "         Gradient evaluations: 119\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 8064\n",
      "         Gradient evaluations: 132\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7088\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 66\n",
      "         Function evaluations: 7820\n",
      "         Gradient evaluations: 128\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 65\n",
      "         Function evaluations: 6966\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000011\n",
      "         Iterations: 67\n",
      "         Function evaluations: 5124\n",
      "         Gradient evaluations: 84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-37ee2511fb7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mnll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mChi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mPEO\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mmini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPEO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_cambiado\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mai\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGravedad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'disp'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mbp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0m\u001b[0;32m   1170\u001b[0m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0;32m   1171\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[0mextra_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'extra_condition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0m\u001b[0;32m    969\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m                              **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mderphi0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgfk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mderphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mgval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mgc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[0;32m    152\u001b[0m                                            **finite_diff_options)\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[0;32m    487\u001b[0m                                      use_one_sided, method)\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Never be here.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mJ_transposed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Gravedad=np.zeros(300)\n",
    "Omega = np.zeros(300)\n",
    "for i in range(300):\n",
    "    Gravedad[i]=9.81 + np.random.normal(loc=0,scale=1)\n",
    "    for j in range(len(yi)):\n",
    "        y_cambiado=yi[j]+np.random.normal( loc=0, scale=sigmay[0], size=len(yi) )\n",
    "        nll = lambda *o: Chi2(*o)\n",
    "        PEO=np.ones(60)\n",
    "        mini = spo.minimize( nll, PEO, args=(hi,y_cambiado,sigmay,ai,Gravedad[i]),options={'disp':True} )\n",
    "    \n",
    "        bp = mini.x[5]\n",
    "        Omega[i] = bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2fa427c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000013\n",
      "         Iterations: 65\n",
      "         Function evaluations: 7881\n",
      "         Gradient evaluations: 129\n"
     ]
    }
   ],
   "source": [
    "P2 = np.ones(len(yi))\n",
    "minimmi = spo.minimize( nll, P2, args=(hi,yi,sigmay,ai,9.8),options={'disp':True} )\n",
    "\n",
    "bestparami = minimmi.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "362a1d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-194-c090bf0ddf27>:2: UserWarning: The following kwargs were not used by contour: 'aspect'\n",
      "  plt.contourf(H2,aspect = 'auto', extent = (Omega.min(),Omega.max(),Gravedad.min(),Gravedad.max()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x25949da3c70>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "H2,binsx,binsy = np.histogram2d(Omega,Gravedad,bins=(30,30))\n",
    "plt.contourf(H2,aspect = 'auto', extent = (Omega.min(),Omega.max(),Gravedad.min(),Gravedad.max()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
